---
layout: default
title: 3-8 Practice Quiz
nav_order: 8
description: "Module 3 Practice Quiz - Data Management in PyTorch"
has_children: false
grand_parent: DL - Pytorch for Deep Learning
parent: Module 3 - Data Management in PyTorch
---

## Practice Quiz - Data Management in PyTorch

**Quiz Type:** Practice Quiz  
**Score:** 4/5 points  
**Note:** This is a practice quiz. While you'll receive a score, it won't count toward your certificate eligibility.

---

### Question 1

**What are the two main PyTorch classes for building data pipelines?**

- [ ] DataLoader and ImageFolder
- [x] **Dataset and DataLoader** ✓
- [ ] BatchLoader and DataSet
- [ ] Dataset and Transform

**Explanation:** Your main tools will be PyTorch's Dataset and DataLoader classes for systematically addressing data pipeline problems.

---

### Question 2

**When creating a custom PyTorch Dataset class, which three methods must you implement?**

- [x] **`__init__`, `__len__`, and `__getitem__`** ✓
- [ ] `download`, `preprocess`, and `__getitem__`
- [ ] `__init__`, `load`, and `transform`
- [ ] `setup`, `load`, and `transform`

**Explanation:** These three methods are what PyTorch needs to work with any dataset:
- `__init__` sets up and locates the data
- `__len__` returns how many samples exist
- `__getitem__` returns a specific sample when given an index

---

### Question 3

**Why does `ToTensor()` scale pixel values from 0-255 down to 0-1?**

- [ ] To make all images have the same brightness
- [ ] To convert the image format from PIL to tensor ✗
- [ ] To reduce the file size of images
- [x] **To keep the math stable and prevent values from exploding during training** ✓

**Incorrect Answer Selected:** "To convert the image format from PIL to tensor"

**Explanation:** While `ToTensor()` does convert from PIL to tensor format, that's separate from the scaling operation. The scaling specifically addresses keeping values in a manageable range for computation.

---

### Question 4

**You have 2,100 training images and set `batch_size=32`. How many batches make up one epoch?**

- [ ] 66 batches, all containing exactly 32 images
- [x] **66 batches - 65 full batches of 32 images, plus 1 batch with 20 images** ✓
- [ ] 65 batches, all containing exactly 32 images
- [ ] 65 batches, with the remaining 20 images discarded

**Explanation:** You get 65 full batches of 32 images, and 1 partial batch with 20 images (the remainder), for a total of 66 batches. One epoch means going through all batches once.

**Calculation:**
- Total images: 2,100
- Batch size: 32
- Full batches: 2,100 ÷ 32 = 65 remainder 20
- Result: 65 full batches + 1 partial batch (20 images) = 66 total batches

---

### Question 5

**[Question not provided in the quiz results]**

---

## Quiz Summary

- **Total Points:** 4/5
- **Pass Status:** ✓ Passed
- **Questions Correct:** 3/4 (Question 3 was incorrect)
- **Attempts Remaining:** 49 left (50 attempts every 24 hours)

### Key Takeaways

1. **Dataset and DataLoader** are the core PyTorch classes for data pipelines
2. Custom datasets require implementing **three essential methods**: `__init__`, `__len__`, and `__getitem__`
3. **`ToTensor()` scaling** keeps values in a stable range (0-1) for neural network training
4. **Batch calculations** account for partial batches when the total doesn't divide evenly

