{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7fe03f9-1ca8-4974-8664-03c6b1d62750",
   "metadata": {},
   "source": [
    "# Neo4j Graph Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e65060c0-d4dc-4e49-aa3c-907b541a0ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-llms-openai\n",
    "%pip install -q llama-index-graph-stores-neo4j\n",
    "%pip install -q llama-index-embeddings-openai\n",
    "#%pip install -q llama-index-llms-azure-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6725aa-e9db-44d7-bc92-e47291ac2c07",
   "metadata": {},
   "source": [
    "https://docs.llamaindex.ai/en/stable/examples/index_structs/knowledge_graph/Neo4jKGIndexDemo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedab8f0-de22-4ea2-9130-5ba3b18672ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall -y llama-index-readers-wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08a3da07-ca21-479e-8f58-be78fb3ffec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For OpenAI\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "# define LLM\n",
    "llm = OpenAI(temperature=0, model=\"gpt-4o\")\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "612298a4-c44b-40da-b66b-dafcc10c3505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import KnowledgeGraphIndex, SimpleDirectoryReader\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.graph_stores.neo4j import Neo4jGraphStore\n",
    "\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9fb8305-b1ed-469d-a5a1-5907aa995ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"neo4j\"\n",
    "password = \"12345678\"\n",
    "url = \"bolt://localhost:7687\"\n",
    "database = \"neo4j\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1d4d348-aa27-40f6-9aa7-82b6b800efa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-readers-file\n",
      "  Using cached llama_index_readers_file-0.4.3-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-readers-file) (4.12.3)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-readers-file) (0.12.10.post1)\n",
      "Collecting pandas (from llama-index-readers-file)\n",
      "  Downloading pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file)\n",
      "  Using cached pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file)\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.6)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2024.12.0)\n",
      "Requirement already satisfied: httpx in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.10.5)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.17.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from pandas->llama-index-readers-file) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from pandas->llama-index-readers-file) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas->llama-index-readers-file)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.18.3)\n",
      "Requirement already satisfied: click in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.25.0)\n",
      "Requirement already satisfied: anyio in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (24.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rdua/work/github/rajdeepd/deeplearningai/knowledge-graphs-rag-neo4j/envjan2025/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.3.1)\n",
      "Using cached llama_index_readers_file-0.4.3-py3-none-any.whl (38 kB)\n",
      "Using cached pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: striprtf, tzdata, pypdf, pandas, llama-index-readers-file\n",
      "Successfully installed llama-index-readers-file-0.4.3 pandas-2.2.3 pypdf-5.1.0 striprtf-0.0.26 tzdata-2024.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install -U llama-index-readers-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f36f0a5f-3e0c-40ef-ac0d-4e0d32509d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llama_dataset import download_llama_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfb89047-8abb-41e1-950b-14a5117d1837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 docs\n"
     ]
    }
   ],
   "source": [
    "#from llama_index.core import SimpleDirectoryReader\n",
    "#from llama_index.core.readers.file.base import SimpleDirectoryReader\n",
    "reader = SimpleDirectoryReader(\n",
    "    input_files=[\"./paul_graham/source_files/source.txt\"]\n",
    ")\n",
    "docs = reader.load_data()\n",
    "print(f\"Loaded {len(docs)} docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "260c70d9-36a6-4e89-9e15-b9591ae92059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:Entity) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_1ed05907 FOR (e:Entity) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '\\n                CREATE CONSTRAINT IF NOT EXISTS FOR (n:Entity) REQUIRE n.id IS UNIQUE;\\n                '\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "graph_store = Neo4jGraphStore(\n",
    "    username=username,\n",
    "    password=password,\n",
    "    url=url,\n",
    "    database=database,\n",
    ")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "\n",
    "# NOTE: can take a while!\n",
    "index = KnowledgeGraphIndex.from_documents(\n",
    "    docs,\n",
    "    storage_context=storage_context,\n",
    "    max_triplets_per_chunk=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d022109b-8597-45c6-bcbc-e86acecf1176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:llama_index.core.indices.knowledge_graph.retrievers:Index was not constructed with embeddings, skipping embedding usage...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    include_text=False, response_mode=\"tree_summarize\"\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What did author write\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a026d82-1bab-4cef-8722-2f862b2ff348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='The author wrote \"Hackers & Painters.\"', source_nodes=[NodeWithScore(node=TextNode(id_='6e6e7c62-3428-4e6f-a20c-07f4bf188ee7', embedding=None, metadata={'kg_rel_texts': [\"['CALLED', 'Hackers & painters']\"], 'kg_rel_map': {'Book': [['CALLED', 'Hackers & painters']]}, 'kg_schema': {'schema': 'Node properties are the following:\\n\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n'}}, excluded_embed_metadata_keys=['kg_rel_map', 'kg_rel_texts'], excluded_llm_metadata_keys=['kg_rel_map', 'kg_rel_texts'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"The following are knowledge sequence in max depth 2 in the form of directed graph like:\\n`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\\n['CALLED', 'Hackers & painters']\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=1000.0)], metadata={'6e6e7c62-3428-4e6f-a20c-07f4bf188ee7': {'kg_rel_texts': [\"['CALLED', 'Hackers & painters']\"], 'kg_rel_map': {'Book': [['CALLED', 'Hackers & painters']]}, 'kg_schema': {'schema': 'Node properties are the following:\\n\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n'}}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c5871e6-2d60-4db5-b7cf-0cad8e042731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>The author wrote \"Hackers & Painters.\"</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8d55096-a3e3-4ef1-99ff-c40d7628a411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:llama_index.core.indices.knowledge_graph.retrievers:Index was not constructed with embeddings, skipping embedding usage...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    include_text=True, response_mode=\"tree_summarize\"\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"Whom did Paul Graham Visit?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfd7276c-d1f1-49b9-acdb-29c3841796d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Paul Graham visited Rich Draves.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6ff10bb-1e22-487b-a813-ea6ed0133575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Clean dataset first\n",
    "graph_store.query(\n",
    "    \"\"\"\n",
    "MATCH (n) DETACH DELETE n\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# NOTE: can take a while!\n",
    "index = KnowledgeGraphIndex.from_documents(\n",
    "    docs,\n",
    "    storage_context=storage_context,\n",
    "    max_triplets_per_chunk=2,\n",
    "    include_embeddings=True,\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    include_text=True,\n",
    "    response_mode=\"tree_summarize\",\n",
    "    embedding_mode=\"hybrid\",\n",
    "    similarity_top_k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "454ce46c-6fef-4c9e-8542-04b84e455729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: e5962aaa-dadc-48de-8509-10ba906c490f: This was when I really started programming. I wrote simple games, a program t...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 426cc155-3024-4fad-bf21-b90d30916731: Occasionally after wrestling for hours with some gruesome bug I'd check Twitt...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 1bd64995-d210-42f1-aad9-704c7c54e2ac: So with my unerring nose for financial opportunity, I decided to write anothe...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: a9666940-fff0-4caa-96c3-24c0b34399d5: So I decided to take a shot at it. It took 4 years, from March 26, 2015 to Oc...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 7420d4ae-3b25-48ad-b6ab-30c8658a6547: It was not, in fact, simply a matter of teaching SHRDLU more words. That whol...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: cf73ff0c-07ae-4c14-bc83-f276edac6db0: What I Worked On\n",
      "\n",
      "February 2021\n",
      "\n",
      "Before college the two main things I worked ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 5962e450-84bb-4144-81ec-3b112b0a8c01: The problem with systems work, though, was that it didn't last. Any program y...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: b003aec3-56de-44bb-910c-22873af53c99: And moreover this was something you could make a living doing. Not as easily ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: a1343994-3344-4aff-ac2a-7f0e6f5c1f6c: I was invited to give a talk at a Lisp conference, so I gave one about how we...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: f8148c1f-f628-434f-a004-3cfd7425e624: That seemed unnatural to me, and on this point the rest of the world is comin...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "#query_engine = index.as_query_engine(\n",
    "#    include_text=False, response_mode=\"tree_summarize\"\n",
    "#)\n",
    "\n",
    "response = query_engine.query(\"What did author write\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4734c335-667b-453b-982a-b388ccc6247d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>The author wrote simple games, a word processor, a book about Lisp hacking, a book on Lisp, and Bel.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03619a1b-e542-43e5-bfcd-f1e4366c583d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envjan2025",
   "language": "python",
   "name": "envjan2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
