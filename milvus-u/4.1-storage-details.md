---
layout: default
title: 4.1 Milvus Architecture - Storage Details
nav_order: 13
description: ""
has_children: false
parent:  Milvus (U)
---

## Milvus Architecture: Storage-Compute Separation

The concept of separating storage and compute resources has gained significant traction in the database landscape, with virtually every modern data system asserting its implementation or intention to adopt such an architecture. However, the precise definition of "storage" and "compute" often differs based on the specific type of data system in question. This section delves into the storage-compute separation architecture as implemented by Milvus, a vector database engineered for high-performance similarity search. Understanding this fundamental design choice is crucial to appreciating Milvus' scalability and efficiency in handling large-scale vector datasets.

### The Dual Nature of Storage-Compute Separation in Milvus

Given the inherent characteristics of vector queries, particularly the need for "re-indexing" as data evolves and the intensive "re-computation" involved in similarity calculations, Milvus' storage-compute separation manifests in two distinct yet interconnected aspects:

#### Decoupling the Processes of Data Ingestion and Query Execution

The lifecycle of data within Milvus, from ingestion to querying, clearly illustrates the separation of processes responsible for generating the persistent storage representation and those dedicated to performing query computations. Consider the typical data flow within a Milvus cluster:

* **Data Ingestion via the Proxy:** End-user applications interact with Milvus through stateless **Proxy** nodes. These proxies are responsible for receiving write requests and channeling the data as messages (`msgs`) into a durable message queue. Popular choices for this message broker include Apache Kafka, Apache Pulsar, or RocksMQ.

* **Segment Generation by DataNodes:** Dedicated **DataNode** workers are tasked with consuming the messages from the message queue. As they process these messages, the DataNodes organize the incoming vector data into logical partitions known as **segments**. Once a segment reaches a certain size or time threshold, it is deemed immutable and is persisted by uploading it to a scalable **object storage** service (such as MinIO, S3, or similar).

* **Orchestration by the Coordination Node (MixCoord):** A central **MixCoord** node plays the crucial role of cluster-level coordination. It monitors the DataNodes and maintains metadata about the generated segments, effectively keeping track of the available data within the object storage.

* **Query Processing by QueryNodes:** When a query request arrives, the MixCoord instructs one or more **QueryNode** workers to load the necessary segments from the object storage into their local memory. These QueryNodes then perform the computationally intensive similarity search operations against the loaded data.

This carefully orchestrated process ensures a clear division of labor. The resource-intensive task of generating and persisting storage files is handled by the DataNodes, while the equally demanding task of query computation is isolated to the QueryNodes. This architectural separation prevents resource contention between these two critical workflows and allows for independent scaling based on the specific workload demands. During periods characterized by a high volume of query requests, the number and computational resources allocated to the QueryNodes can be dynamically increased. Conversely, during phases of intense data ingestion, the DataNodes can be scaled out to handle the increased write pressure without impacting query performance.

#### Separating Data Storage Location from Computation Location

Beyond the separation of processes, Milvus' architecture also distinctly separates **where the data physically resides (object storage)** from **where the query computations are performed (QueryNode memory)**. The design choice of making Milvus segments immutable is fundamental to this separation. Once a segment is written to object storage by a DataNode, it is never modified. This immutability offers several advantages, including simplified data management, improved data consistency, and the inherent support for "write once, read many" scenarios, which are typical in analytical workloads and vector similarity search. The QueryNodes fetch and load these immutable segments into their local memory only when required for query processing, ensuring that the persistent storage layer remains decoupled from the transient computational layer.